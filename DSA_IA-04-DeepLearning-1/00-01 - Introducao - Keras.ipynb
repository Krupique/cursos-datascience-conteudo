{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É uma subárea da inteligência artificial:\n",
    "\n",
    "<img width=600px src=\"assets/deep01.png\"/>\n",
    "\n",
    "A inteligência artificial busca ensinar computadores a executar tarefas que são fáceis para os seres humanos, mas que não podem ser descritas formalmente ou são muito complexas para computadores, como reconhecimento de voz e imagens.<br/>\n",
    "Se desenharmos um gráfico mostrando como os conceitos de redes neurais são construídos um sobre o outro, o gráfico é profundo, com muitas camadas. Por essa razão, nós chamamos esta abordagem de Deep Learning.\n",
    "\n",
    "<img width=400px src=\"assets/deep02.png\"/>\n",
    "\n",
    "**Como funciona Deep Learning**<br/>\n",
    "O processo de aprendizagem dos algoritmos de deep learning se baseia no processo de aprendizagem do nosso cérebro, principalmente na parte conhecida como córtex visual, o chamado processo da Aprendizagem Hierárquica.\n",
    "\n",
    "\n",
    "<img width=600px src=\"assets/deep03.png\"/>\n",
    "\n",
    "\n",
    "**Deep Neural Networks**<br/>\n",
    "A definição mais simples de Deep Learning é que ela é uma rede neural com múltiplas camadas ocultas.<br/>\n",
    "O uso de várias camadas ocultas permite uma acumulação mais sofisticada de elementos simples a outros mais complexos. Pode-se considerar dois aspectos de complexidade da arquitetura de um modelo:\n",
    "* Número de neurônios por camada;\n",
    "* Número de camadas;\t\n",
    "\n",
    "Principais frameworks para deep learning:\n",
    "\n",
    "<img width=800px src=\"assets/deep04.png\"/>\n",
    "\n",
    "\n",
    "**Convolutional Neural Networks**<br/>\n",
    "\n",
    "<img width=400px src=\"assets/deep05.png\"/>\n",
    "\n",
    "\n",
    "**Recurrent Neural Networks**<br/>\n",
    "A ideia por trás das RNNs é fazer uso de informações sequenciais, elas constituem uma ampla classe de redes cuja evolução do estado depende tanto da entrada corrente quanto do estado atual. Elas têm uma memória, que capturam as informações que foram calculadas até o momento.<br/>\n",
    "Atualmente as RNNs são bastante utilizadas em processamento de linguagem natural. O tipo mais comumente usado de RNNs são as LSTMs (Long short-term memory), que são muito melhores na captura de dependências de longo prazo do que RNNs padrões.<br/>\n",
    "A arquitetura usada em RNNs é adequada para permitir o processamento de informação sequencial (textos, áudio e vídeo).\n",
    "\n",
    "<img width=300px src=\"assets/deep06.png\"/>\n",
    "\n",
    "\n",
    "**LSTM (Long Short-Term Memory)**<br/>\n",
    "As LSTMs  consistem em um conjunto de sub redes conectadas recorrentemente. Essas sub redes, chamadas de blocos de memória, podem ser consideradas uma metáfora de chips de memória.<br/>\n",
    "Cada bloco possui uma ou mais células de memória auto conectadas e três unidades de multiplicação que definem a operação que deve ser realizada, as portas de entrada, saída e de esquecimento.\n",
    "\n",
    "\n",
    "<img width=300px src=\"assets/deep07.png\"/>\n",
    "\n",
    "**Função de ativação (Softmax)**<br/>\n",
    "A função softmax serve para converter o resultado previsto pelo modelo em uma lista de probabilidades de valores.\n",
    "\n",
    "\n",
    "\n",
    "**Stochastic Gradient Descent**<br/>\n",
    "O treinamento de uma rede neural é convertido em um problema de otimização, cujo objetivo é minimizar o erro cometido pela rede, quando considerados todos os exemplos de treinamento.<br/>\n",
    "A ideia do algoritmo é realizar de forma iterativa pequenas alterações no vetor de parâmetros de forma a levar o vetor na maior descida nessa superfície.\n",
    "\n",
    "<img width=300px src=\"assets/deep08.png\"/>\n",
    "\n",
    "O gradiente de uma função f mede o quanto f varia uma vez que seus argumentos são alterados. Se f for uma função multivariada de n variáveis, então o gradiente negativo de f é um vetor n-dimensional cujas componentes são as derivadas parciais de f.<br/>\n",
    "\n",
    "O problema do gradiente descendente é que além de ser computacionalmente intensivo, você precisa calcular o gradiente de cada elemento do seu conjunto de treinamento, o que pode levar muito tempo em grandes conjuntos de dados.<br/>\n",
    "\n",
    "A solução encontrada para esse problema foi o Stochastic Gradient Descent (SGD) que é uma versão do gradiente descendente, em que trabalhamos com amostras aleatórias.<br/>\n",
    "\n",
    "Tanto no Gradiente Descendente (DG) quanto no Stochastic Gradient Descent (SGD), você atualiza um conjunto de parâmetros de forma iterativa para minimizar uma função de erro. Porém, enquanto com DG, você precisa percorrer todas as amostras em seu conjunto de treinamento para fazer uma única atualização para um parâmetro em uma iteração particular, com SGD, por outro lado, você usa somente uma amostra de treinamento de seu conjunto de treinamento para fazer a atualização para um parâmetro em uma iteração específica.<br/>\n",
    "\n",
    "SGD é uma aproximação de gradiente descendente e quanto mais lotes processados pela rede neural (ou seja, mais amostra aleatórias), melhor a aproximação.\n",
    "A implementação do SGD compreende:\n",
    "1. Amostragem aleatória de um lote de dados do conjunto de dados total.\n",
    "2. Executar a rede para frente e para trás para calcular o gradiente (com dados gerados no item 1).\n",
    "3. Aplicar a atualização de descida de gradiente.\n",
    "4. Repetir os passos 1 a 3 até que a convergência ou o ciclo seja interrompido por outro mecanismo, ou seja, o número de épocas (epochs).\n",
    "\n",
    "**Momentum e Learning Rate**<br/>\n",
    "Os pesos da rede neural podem ser atualizados conforme os dados são processados e os erros são calculados (abordagem conhecida como online learning) ou ao final do processo (abordagem conhecida como batch learning).\n",
    "\n",
    "<img width=300px src=\"assets/deep09.png\"/>\n",
    "\n",
    "O principal parâmetro que controla a atualização dos pesos é conhecido com learning rate, normalmente é atribuído valores bem pequenos para esse parâmetro, como 0.1 ou 0.01.<br/>\n",
    "Dois parâmetros adicionais podem ser usados no processo de atualização dos pesos.<br/>\n",
    "* **Momentum**: Incorpora as propriedades da atualização de pesos anterior e faz com que os pesos continuem sendo atualizados na mesma direção mesmo quando o erro diminui.\n",
    "* **Learning rate decay**: É usado para diminuir o valor do learning rate conforme os erros diminuem.\n",
    "\n",
    "\n",
    "**Regularização e Dropout**<br/>\n",
    "A regularização é um método que busca melhorar a capacidade de generalização dos algoritmos de aprendizado por meio de alguma restrição durante a fase de treinamento. A regularização ajuda a evitar o overfitting e melhora a generalização do modelo.<br/>\n",
    "\n",
    "O seu objetivo em Deep Learning é encontrar um modelo que seja grande e profundo o suficiente para representar a complexidade nos dados e que possa ser aplicado a novos conjuntos de dados, com um bom desempenho. A regularização é uma das formas usadas para se alcançar esse objetivo.<br/>\n",
    "\n",
    "A regularização L1 e L2 basicamente penalizam os coeficientes. Mas elas possuem diferentes propriedades e são utilizadas de diferentes maneiras. A magnitude dos coeficientes é penalizada e os erros são minimizados entre os valores previstos e os valores observados.<br/>\n",
    "\n",
    "Já o Dropout desativa os neurônios da camada associada com alguma probabilidade p. Desativar o neurônio basicamente significa mudar o valor de saída para zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras é uma biblioteca para rede neural de alto-nível escrita em Python e roda como frontend em TensorFlow ou Theano. O bom disso é que você pode substituir uma rede neural por outra utilizando Keras. Ela foi desenvolvida para facilitar experimentações rápidas, isto é, sem que você tenha que dominar cada um dos backgrounds, de maneira rápida e eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa os pacotes\n",
    "import tensorflow as tf\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garante a reproducividade do código\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados e separa as variáveis independentes (x) e dependente (y)\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter = \",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa os dados entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.33, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos em Keras são definidos como uma sequência de camadas. Isto facilita a criação do modelo, bastando inserir uma camada por vez até que estejamos satisfeitos com a topologia da rede. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira coisa a se fazer é garantir que a camada de entrada tem o número correto de inputs. Isto pode ser especificado enquanto criando a primeira camada com o argumento ‘input_dim’,  atribuindo-lhe 8, para o variáveis de entrada. No exemplo a estrutura de rede é fully-connected com 3 camadas. Isto é, todos os neurônios se comunicam antes da saída."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós podemos especificar o número de neurônios na camada como primeiro argumento, o método de inicialização como segundo argmento sendo ‘init’ e especificar a função de ativação utilizando o argumento ‘activation’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, nós inicializamos o peso da rede para um pequeno número randômico gerado a partir de uma distribuição uniforme (‘uniform’), entre 0 e 0.05, nesse caso, porque esse é o peso padrão da distribuição uniforme no Keras. Uma alternativa tradicional seria o ‘normal’, gerando assim pequenos números randômicos a partir de uma distribuição gaussiana. Também será usada a função de ativação ‘relu’ nas primeiras duas camadas e a função sigmoide na camada de saída. O resultado deverá ser algo entre 0 e 1 com um threshold  padrão de 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construindo o código, você pode notar que a primeira camada tem 12 neurônios e espera 8 variáveis de entrada. A segunda camada  possui 8 neurônios e finalmente a saída tem 1 neurônio fazendo a predição da classe alvo (tendência a desenvolver diabetes ou não)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o modelo\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=12, input_shape = (8,), kernel_initializer = 'glorot_uniform', activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(units=6, kernel_initializer = 'glorot_uniform', activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid', kernel_initializer = 'uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A compilação do modelo usa uma eficiente biblioteca numérica de backend, como Theano or TensorFlow. O backend automaticamente escolhe o melhor caminho para representar a rede e fazer predições.\n",
    "\n",
    "Será necessário em algum momento especificar a função de perda para avaliar os pesos. Nesse exemplo foi definido o uso da função de perda logarítmica, definido em Keras como “binary_crossentropy”. Também é utilizado o algoritmo Stochastic Gradient Descent para otimização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compila o modelo\n",
    "model.compile(loss = 'binary_crossentropy', \n",
    "              optimizer = SGD(learning_rate = 0.01, momentum = 0.9, nesterov = True), \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 1s 5ms/step - loss: 0.7378 - accuracy: 0.6419\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6508 - accuracy: 0.6536\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6510 - accuracy: 0.6471\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6486 - accuracy: 0.6510\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6451 - accuracy: 0.6510\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6490 - accuracy: 0.6484\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6481 - accuracy: 0.6510\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6479 - accuracy: 0.6510\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6464 - accuracy: 0.6510\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6467 - accuracy: 0.6497\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6465 - accuracy: 0.6510\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6511 - accuracy: 0.6471\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.6510\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6483 - accuracy: 0.6510\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.6510\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6475 - accuracy: 0.6510\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6479 - accuracy: 0.6523\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.6510\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6480 - accuracy: 0.6497\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6475 - accuracy: 0.6510\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6475 - accuracy: 0.6510\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6499 - accuracy: 0.6497\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.6480 - accuracy: 0.6510\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6479 - accuracy: 0.6510\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6474 - accuracy: 0.6510\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6480 - accuracy: 0.6510\n",
      "Epoch 27/150\n",
      "44/77 [================>.............] - ETA: 0s - loss: 0.6450 - accuracy: 0.6545"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Executa o modelo e valida nos mesmos dados em que foi criado (treino)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1221\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1219\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1221\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1223\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:436\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 436\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:295\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 295\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    298\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:316\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    313\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    314\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 316\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    319\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:354\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    353\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 354\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    357\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:1032\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1032\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:1104\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1103\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1104\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py:554\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    552\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t  \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m--> 554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py:550\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    549\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 550\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    552\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1149\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \n\u001b[0;32m   1128\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1149\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1115\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1114\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1116\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Executa o modelo e valida nos mesmos dados em que foi criado (treino)\n",
    "model.fit(X, Y, epochs = 150, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utlizar outro algoritmo para otimização, como o Gradient descent adm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compila o modelo com outro otimizador\n",
    "model.compile(loss = 'binary_crossentropy', \n",
    "              optimizer = 'adam', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "autotune = tf.data.experimental.AUTOTUNE\n",
    "batch_size = 8\n",
    "epochs = 100\n",
    "lr = 0.1\n",
    "beta1 = 0.1\n",
    "beta2 = 0.1\n",
    "ep = 1e-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(optimizer = Adam(learning_rate = lr), \n",
    "                                #beta_1 = beta1, \n",
    "                                #beta_2 = beta2, \n",
    "                                #epsilon = ep),\n",
    "               loss = 'binary_crossentropy', \n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 1s 4ms/step - loss: 0.8179 - accuracy: 0.5221\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.6146\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.6315\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6767 - accuracy: 0.6146\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6704 - accuracy: 0.6484\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6673 - accuracy: 0.6589\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.6380\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6585 - accuracy: 0.6589\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.6484\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.6484\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.6471\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.6471\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6558 - accuracy: 0.6536\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6484\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.6549\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.6549\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6466 - accuracy: 0.6471\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.6484\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6732\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.6654\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.6836\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.6641\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.6419\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6262 - accuracy: 0.6497\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.6680\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6784\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.6680\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6103 - accuracy: 0.6719\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6228 - accuracy: 0.6680\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6040 - accuracy: 0.6810\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.6732\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6069 - accuracy: 0.6849\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.6901\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6144 - accuracy: 0.6758\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6099 - accuracy: 0.6875\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.6810\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.6758\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.6966\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.6797\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.6719\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.6888\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.7005\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5972 - accuracy: 0.6797\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.6836\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.6901\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.6966\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.6771\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7005\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.7070\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5879 - accuracy: 0.7031\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.6875\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.7083\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.6966\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.7070\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.6940\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6849\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5924 - accuracy: 0.7005\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.6914\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 0.6836\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.7083\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.6758\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.7005\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.6992\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6008 - accuracy: 0.6862\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.6953\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.7031\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.7057\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.6966\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.6836\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.7018\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5801 - accuracy: 0.7109\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.6888\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.7057\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7161\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.7109\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.7018\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.6901\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5885 - accuracy: 0.7044\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.6836\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.7070\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5843 - accuracy: 0.6823\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5890 - accuracy: 0.6875\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.6953\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5848 - accuracy: 0.6784\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.6888\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.6888\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.6875\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.7005\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5843 - accuracy: 0.7005\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.6849\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5828 - accuracy: 0.6875\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5912 - accuracy: 0.6849\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.6888\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.6940\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7148\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.7018\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.7109\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5908 - accuracy: 0.6823\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.7148\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.7253\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.6849\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5865 - accuracy: 0.6797\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.7122\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.6836\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.7018\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5786 - accuracy: 0.7096\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.7331\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5863 - accuracy: 0.6862\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.7083\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5670 - accuracy: 0.7031\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.7031\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.7122\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.6966\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.6901\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.6927\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.7096\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.7214\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.7044\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5747 - accuracy: 0.7240\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.6940\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7044\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5714 - accuracy: 0.7148\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5758 - accuracy: 0.7044\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5737 - accuracy: 0.7174\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5777 - accuracy: 0.7018\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5694 - accuracy: 0.7135\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.6862\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5660 - accuracy: 0.7031\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5610 - accuracy: 0.7253\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5789 - accuracy: 0.6953\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.7031\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5899 - accuracy: 0.6849\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5749 - accuracy: 0.6966\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5705 - accuracy: 0.6966\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5752 - accuracy: 0.7201\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5840 - accuracy: 0.6992\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.7109\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.7070\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.7266\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.7279\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.7083\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7201\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.7044\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.7122\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.7161\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7070\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.7148\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.7005\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5716 - accuracy: 0.7148\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26995ab8fa0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executa o modelo e valida nos mesmos dados em que foi criado (treino)\n",
    "model.fit(X, Y, epochs = 150, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O treinamento da rede neural foi feita sobre o conjunto completo de dados e a performance da rede neural pode ser avaliada no mesmo conjunto de dados, o que nos dará uma boa ideia do quão bem modelada foi a rede. Utiliza-se a função evaluate() no modelo, passando o mesmo número de inputs e outputs usados no treinamento. Isto gerará uma predição para cada entrada e saída e coletará pontuação, incluindo média de perda e qualquer métrica que tenha sido configurada, como a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7227\n",
      "accuracy: 72.27%\n"
     ]
    }
   ],
   "source": [
    "# Avalia os resultados do modelo\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Executa o modelo e faz validação em um conjunto de dados separado automaticamente para teste\n",
    "model.fit(X, Y, validation_split = 0.33, epochs = 150, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Executa o modelo e faz validação em um conjunto de dados separado manualmente para teste\n",
    "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs = 150, batch_size = 10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
