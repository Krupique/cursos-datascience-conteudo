{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines - Reconhecimento de Imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconhecimento de Imagens com Modelos de Regressão Logística e SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento\n",
    "def preprocess():\n",
    "   \n",
    "    # Carrega o dataset\n",
    "    mat = loadmat('data/mnist_all.mat')  \n",
    "\n",
    "    n_feature = mat.get(\"train1\").shape[1]\n",
    "    n_sample = 0\n",
    "    for i in range(10):\n",
    "        n_sample = n_sample + mat.get(\"train\" + str(i)).shape[0]\n",
    "    n_validation = 1000\n",
    "    n_train = n_sample - 10 * n_validation\n",
    "\n",
    "    # Constrói o conjunto de validação\n",
    "    validation_data = np.zeros((10 * n_validation, n_feature))\n",
    "    for i in range(10):\n",
    "        validation_data[i * n_validation:(i + 1) * n_validation, :] = mat.get(\"train\" + str(i))[0:n_validation, :]\n",
    "\n",
    "    # Labels de validação\n",
    "    validation_label = np.ones((10 * n_validation, 1))\n",
    "    for i in range(10):\n",
    "        validation_label[i * n_validation:(i + 1) * n_validation, :] = i * np.ones((n_validation, 1))\n",
    "\n",
    "    # Atributos e labels de treino\n",
    "    train_data = np.zeros((n_train, n_feature))\n",
    "    train_label = np.zeros((n_train, 1))\n",
    "    temp = 0\n",
    "    for i in range(10):\n",
    "        size_i = mat.get(\"train\" + str(i)).shape[0]\n",
    "        train_data[temp:temp + size_i - n_validation, :] = mat.get(\"train\" + str(i))[n_validation:size_i, :]\n",
    "        train_label[temp:temp + size_i - n_validation, :] = i * np.ones((size_i - n_validation, 1))\n",
    "        temp = temp + size_i - n_validation\n",
    "\n",
    "    # Atributos e labels de teste\n",
    "    n_test = 0\n",
    "    for i in range(10):\n",
    "        n_test = n_test + mat.get(\"test\" + str(i)).shape[0]\n",
    "    test_data = np.zeros((n_test, n_feature))\n",
    "    test_label = np.zeros((n_test, 1))\n",
    "    temp = 0\n",
    "    for i in range(10):\n",
    "        size_i = mat.get(\"test\" + str(i)).shape[0]\n",
    "        test_data[temp:temp + size_i, :] = mat.get(\"test\" + str(i))\n",
    "        test_label[temp:temp + size_i, :] = i * np.ones((size_i, 1))\n",
    "        temp = temp + size_i\n",
    "\n",
    "    # Remove atributos que não são relevantes para o modelo\n",
    "    sigma = np.std(train_data, axis=0)\n",
    "    index = np.array([])\n",
    "    for i in range(n_feature):\n",
    "        if (sigma[i] > 0.001):\n",
    "            index = np.append(index, [i])\n",
    "    train_data = train_data[:, index.astype(int)]\n",
    "    validation_data = validation_data[:, index.astype(int)]\n",
    "    test_data = test_data[:, index.astype(int)]\n",
    "\n",
    "    # Normalização dos dados com escala entre 0 e 1\n",
    "    train_data /= 255.0\n",
    "    validation_data /= 255.0\n",
    "    test_data /= 255.0\n",
    "\n",
    "    return train_data, train_label, validation_data, validation_label, test_data, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computa a função de erro e gradiente de um modelo de 2 classes com Regressão Logística\n",
    "def blrObjFunction(initialWeights, *args):\n",
    "    \n",
    "    train_data, labeli = args\n",
    "\n",
    "    n_data = train_data.shape[0]\n",
    "    n_features = train_data.shape[1]\n",
    "\n",
    "    w = np.reshape(initialWeights,(716, 1))\n",
    "\n",
    "    dataones = np.ones((n_data,1))\n",
    "    t_data = np.hstack((dataones,train_data))\n",
    "\n",
    "    sigin=np.dot(t_data,w)\n",
    "\n",
    "    thetaN=sigmoid(sigin)\n",
    "\n",
    "    lntheta=np.log(thetaN)\n",
    "\n",
    "    product1=np.multiply(labeli,lntheta)\n",
    "\n",
    "    lntheta2=np.log(1-thetaN)\n",
    "\n",
    "    product2 = np.multiply((1.0 - labeli),lntheta2)\n",
    "\n",
    "    s=product1+product2\n",
    "\n",
    "    e = np.sum(s)\n",
    "\n",
    "    error = -e/n_data\n",
    "\n",
    "    ty=thetaN-labeli\n",
    "\n",
    "    pr1 = np.dot(t_data.T,ty)\n",
    "\n",
    "    e_grad =pr1/n_data\n",
    "\n",
    "    error_grad=e_grad.flatten()\n",
    "\n",
    "    return error, error_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões\n",
    "def blrPredict(W, data):\n",
    "   \n",
    "    label = np.zeros((data.shape[0], 1))\n",
    "    dataones = np.ones((data.shape[0],1))\n",
    "    t_data = np.hstack((dataones,data))\n",
    "\n",
    "    a = sigmoid(np.dot(t_data, W))\n",
    "\n",
    "    label = np.argmax(a, axis=1)\n",
    "\n",
    "    label=label.reshape((data.shape[0],1))\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificação Multi-classe com Regressão Logística\n",
    "def mlrObjFunction(params, *args):\n",
    "\n",
    "    train_data, labeli = args\n",
    "    n_data = train_data.shape[0]\n",
    "    n_feature = train_data.shape[1]\n",
    "    n_class=labeli.shape[1]\n",
    "\n",
    "    w=params.reshape((n_feature+1,n_class))\n",
    "\n",
    "    dataones = np.ones((n_data,1))\n",
    "    t_data = np.hstack((dataones,train_data))\n",
    "\n",
    "    expin=np.dot(t_data,w)\n",
    "\n",
    "    e = np.exp(expin / 1.0)\n",
    "    theta = e / np.sum(e,axis=1).reshape(e.shape[0],1)\n",
    "\n",
    "    lntheta=np.log(theta)\n",
    "\n",
    "    er=np.multiply(labeli,lntheta)\n",
    "\n",
    "    s=np.sum(er)\n",
    "\n",
    "    error=-s/n_data\n",
    "\n",
    "    ty=theta-labeli\n",
    "\n",
    "    egrad=np.dot(t_data.T,ty)\n",
    "\n",
    "    egrad2=egrad/n_data\n",
    "\n",
    "    error_grad=egrad2.flatten()\n",
    "\n",
    "    return error, error_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões Multi-classe\n",
    "def mlrPredict(W, data):\n",
    "\n",
    "    dataones = np.ones((data.shape[0],1))\n",
    "    t_data = np.hstack((dataones,data))\n",
    "\n",
    "    a = np.exp(np.dot(t_data, W))\n",
    "\n",
    "    label = np.argmax(a, axis=1)\n",
    "\n",
    "    label=label.reshape((data.shape[0],1))\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressão Logística\n",
    "train_data, train_label, validation_data, validation_label, test_data, test_label = preprocess()\n",
    "\n",
    "# Número de classes\n",
    "n_class = 10\n",
    "\n",
    "# Número de exemplos de treinamento\n",
    "n_train = train_data.shape[0]\n",
    "\n",
    "# Número de atributos\n",
    "n_feature = train_data.shape[1]\n",
    "\n",
    "Y = np.zeros((n_train, n_class))\n",
    "for i in range(n_class):\n",
    "    Y[:, i] = (train_label == i).astype(int).ravel()\n",
    "\n",
    "# Regressão Logística com Gradiente Descendente\n",
    "W = np.zeros((n_feature + 1, n_class))\n",
    "initialWeights = np.zeros((n_feature + 1, 1))\n",
    "opts = {'maxiter': 100}\n",
    "for i in range(n_class):\n",
    "    labeli = Y[:, i].reshape(n_train, 1)\n",
    "    args = (train_data, labeli)\n",
    "    nn_params = minimize(blrObjFunction, initialWeights, jac=True, args=args, method='CG', options=opts)\n",
    "    W[:, i] = nn_params.x.reshape((n_feature + 1,))\n",
    "\n",
    "# Imprime Acurária\n",
    "predicted_label = blrPredict(W, train_data)\n",
    "print('\\n Acurácia no Conjunto de Dados de Treino: ' + str(100 * np.mean((predicted_label == train_label).astype(float))) + '%')\n",
    "\n",
    "predicted_label = blrPredict(W, validation_data)\n",
    "print('\\n Acurácia no Conjunto de Dados de Validação: ' + str(100 * np.mean((predicted_label == validation_label).astype(float))) + '%')\n",
    "\n",
    "predicted_label = blrPredict(W, test_data)\n",
    "print('\\n Acurácia no Conjunto de Dados de Teste: ' + str(100 * np.mean((predicted_label == test_label).astype(float))) + '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Support Vector Machines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - Kernel Linear\n",
    "train_label=np.ravel(train_label)\n",
    "validation_label=np.ravel(validation_label)\n",
    "test_label=np.ravel(test_label)\n",
    "\n",
    "print (\"***** SVM Kernel Linear *****\")\n",
    "\n",
    "clf = SVC(kernel = 'linear')\n",
    "clf.fit(train_data, train_label)\n",
    "\n",
    "# Imprime Acurária\n",
    "predicted_label= clf.predict(np.array(train_data))\n",
    "print('\\n Acurácia no Conjunto de Dados de Treino usando SVM com Kernel Linear: ' + str(100 * np.mean((predicted_label == train_label).astype(float))) + '%')\n",
    "\n",
    "predicted_label= clf.predict(np.array(validation_data))\n",
    "print('\\n Acurácia no Conjunto de Dados de Validação usando SVM com Kernel Linear: ' + str(100 * np.mean((predicted_label == validation_label).astype(float))) + '%')\n",
    "\n",
    "predicted_label= clf.predict(np.array(test_data))\n",
    "print('\\n Acurácia no Conjunto de Dados de Teste usando SVM com Kernel Linear: ' + str(100 * np.mean((predicted_label == test_label).astype(float))) + '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel RBF com Gamma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - Kernel RBF com gamma = 1\n",
    "print (\"***** SVM Kernel RBF com gamma = 1 *****\")\n",
    "\n",
    "clf = SVC(kernel='rbf',gamma=1.0)\n",
    "clf.fit(train_data, train_label)\n",
    "\n",
    "# Imprime Acurária\n",
    "predicted_label= clf.predict(np.array(train_data))\n",
    "print('\\n Acurácia no Conjunto de Dados de Treino usando SVM com Kernel RBF com gamma=1: ' + str(100 * np.mean((predicted_label == train_label).astype(float))) + '%')\n",
    "\n",
    "predicted_label= clf.predict(np.array(validation_data))\n",
    "print('\\n Acurácia no Conjunto de Dados de Validação usando SVM com Kernel RBF com gamma=1: ' + str(100 * np.mean((predicted_label == validation_label).astype(float))) + '%')\n",
    "\n",
    "predicted_label= clf.predict(np.array(test_data))\n",
    "print('\\n Acurácia no Conjunto de Dados de Teste usando SVM com Kernel RBF com gamma=1: ' + str(100 * np.mean((predicted_label == test_label).astype(float))) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel RBF com Gamma default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - Kernel RBF com gamma default\n",
    "\n",
    "print (\"***** SVM Kernel RBF com gamma default *****\")\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(train_data, train_label)\n",
    "\n",
    "# Imprime Acurária\n",
    "predicted_label= clf.predict(np.array(train_data))\n",
    "print('\\n Acurácia no Conjunto de Dados de Treino usando SVM com Kernel RBF com gamma default: ' + str(100 * np.mean((predicted_label == train_label).astype(float))) + '%')\n",
    "\n",
    "predicted_label= clf.predict(np.array(validation_data))\n",
    "print('\\n Acurácia no Conjunto de Dados de Validação usando SVM com Kernel RBF com gamma defaut: ' + str(100 * np.mean((predicted_label == validation_label).astype(float))) + '%')\n",
    "\n",
    "predicted_label= clf.predict(np.array(test_data))\n",
    "print('\\n Acurácia no Conjunto de Dados de Treino usando SVM com Kernel RBF com gamma default: ' + str(100 * np.mean((predicted_label == test_label).astype(float))) + '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel RBF diferentes valores para C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - Kernel RBF com diferentes valores para C\n",
    "\n",
    "print (\"***** SVM Kernel RBF com diferentes valores para C *****\")\n",
    "\n",
    "print (\"Valor de C: 1\")\n",
    "\n",
    "clf = SVC(kernel = 'rbf', C = 1.0)\n",
    "clf.fit(train_data, train_label)\n",
    "\n",
    "# Imprime Acurária\n",
    "predicted_label= clf.predict(np.array(train_data))\n",
    "print('\\n Acurácia no Conjunto de Dados de Treino usando SVM com Kernel RBF e C=1: ' + str(100 * np.mean((predicted_label == train_label).astype(float))) + '%')\n",
    "\n",
    "predicted_label= clf.predict(np.array(validation_data))\n",
    "print('\\n Acurácia no Conjunto de Dados de Validação usando SVM com Kernel RBF e C=1: ' + str(100 * np.mean((predicted_label == validation_label).astype(float))) + '%')\n",
    "\n",
    "predicted_label= clf.predict(np.array(test_data))\n",
    "print('\\n Acurácia no Conjunto de Dados de Teste usando SVM com Kernel RBF e C=1: ' + str(100 * np.mean((predicted_label == test_label).astype(float))) + '%')\n",
    "\n",
    "for i in range(10,110,10):\n",
    "\n",
    "    print (\"Valor de C:\" + str(i))\n",
    "    clf = SVC(kernel = 'rbf', C = i)\n",
    "    clf.fit(train_data, train_label)\n",
    "    \n",
    "    predicted_label = clf.predict(np.array(train_data))\n",
    "    print('\\n Acurácia no Conjunto de Dados de Treino usando SVM com Kernel RBF e diferentes valores de C: ' + str(100 * np.mean((predicted_label == train_label).astype(float))) + '%')\n",
    "\n",
    "    predicted_label = clf.predict(np.array(validation_data))\n",
    "    print('\\n Acurácia no Conjunto de Dados de Validação usando SVM com Kernel RBF e diferentes valores de C: ' + str(100 * np.mean((predicted_label == validation_label).astype(float))) + '%')\n",
    "\n",
    "    predicted_label = clf.predict(np.array(test_data))\n",
    "    print('\\n Acurácia no Conjunto de Dados de Teste usando SVM com Kernel RBF e diferentes valores de C: ' + str(100 * np.mean((predicted_label == test_label).astype(float))) + '%')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
