{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métodos Ensemble**<br/>\n",
    "Qual algoritmo vai ter o melhor desempenho para resolver o problema? <br/>\n",
    "A melhor forma de melhorar a acurácia de um modelo é juntar vários modelos diferentes a fim de criar um modelo final mais preciso. <br/>\n",
    "Métodos Ensemble são uma categoria de algoritmos de Machine Learning e podem ser usados tanto em Aprendizagem Supervisionada quanto em aprendizagem não supervisionada.\n",
    "Construção de Ensembles consistem em dois passos:\n",
    "1. Construir vários modelos;\n",
    "2. Combinar suas estimativas.\n",
    "\n",
    "<img src=\"assets/ensemble01.png\"/><br/>\n",
    "<img src=\"assets/ensemble02.png\"/><br/>\n",
    "<img src=\"assets/ensemble03.png\"/><br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de dados\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento\n",
    "data = scale(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis preditoras e variável target\n",
    "X = data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do Classificador\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(), max_samples = 0.5, max_features = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=KNeighborsClassifier(), max_features=0.5,\n",
       "                  max_samples=0.5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2*n_jobs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0merror_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Evaluate a score by cross-validation\n",
      "\n",
      "Read more in the :ref:`User Guide <cross_validation>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "estimator : estimator object implementing 'fit'\n",
      "    The object to use to fit the data.\n",
      "\n",
      "X : array-like of shape (n_samples, n_features)\n",
      "    The data to fit. Can be for example a list, or an array.\n",
      "\n",
      "y : array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None\n",
      "    The target variable to try to predict in the case of\n",
      "    supervised learning.\n",
      "\n",
      "groups : array-like of shape (n_samples,), default=None\n",
      "    Group labels for the samples used while splitting the dataset into\n",
      "    train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "    instance (e.g., :class:`GroupKFold`).\n",
      "\n",
      "scoring : str or callable, default=None\n",
      "    A str (see model evaluation documentation) or\n",
      "    a scorer callable object / function with signature\n",
      "    ``scorer(estimator, X, y)`` which should return only\n",
      "    a single value.\n",
      "\n",
      "    Similar to :func:`cross_validate`\n",
      "    but only a single metric is permitted.\n",
      "\n",
      "    If None, the estimator's default scorer (if available) is used.\n",
      "\n",
      "cv : int, cross-validation generator or an iterable, default=None\n",
      "    Determines the cross-validation splitting strategy.\n",
      "    Possible inputs for cv are:\n",
      "\n",
      "    - None, to use the default 5-fold cross validation,\n",
      "    - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "    - :term:`CV splitter`,\n",
      "    - An iterable yielding (train, test) splits as arrays of indices.\n",
      "\n",
      "    For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "    either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "    other cases, :class:`KFold` is used. These splitters are instantiated\n",
      "    with `shuffle=False` so the splits will be the same across calls.\n",
      "\n",
      "    Refer :ref:`User Guide <cross_validation>` for the various\n",
      "    cross-validation strategies that can be used here.\n",
      "\n",
      "    .. versionchanged:: 0.22\n",
      "        ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    Number of jobs to run in parallel. Training the estimator and computing\n",
      "    the score are parallelized over the cross-validation splits.\n",
      "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "    for more details.\n",
      "\n",
      "verbose : int, default=0\n",
      "    The verbosity level.\n",
      "\n",
      "fit_params : dict, default=None\n",
      "    Parameters to pass to the fit method of the estimator.\n",
      "\n",
      "pre_dispatch : int or str, default='2*n_jobs'\n",
      "    Controls the number of jobs that get dispatched during parallel\n",
      "    execution. Reducing this number can be useful to avoid an\n",
      "    explosion of memory consumption when more jobs get dispatched\n",
      "    than CPUs can process. This parameter can be:\n",
      "\n",
      "        - None, in which case all the jobs are immediately\n",
      "          created and spawned. Use this for lightweight and\n",
      "          fast-running jobs, to avoid delays due to on-demand\n",
      "          spawning of the jobs\n",
      "\n",
      "        - An int, giving the exact number of total jobs that are\n",
      "          spawned\n",
      "\n",
      "        - A str, giving an expression as a function of n_jobs,\n",
      "          as in '2*n_jobs'\n",
      "\n",
      "error_score : 'raise' or numeric, default=np.nan\n",
      "    Value to assign to the score if an error occurs in estimator fitting.\n",
      "    If set to 'raise', the error is raised.\n",
      "    If a numeric value is given, FitFailedWarning is raised.\n",
      "\n",
      "    .. versionadded:: 0.20\n",
      "\n",
      "Returns\n",
      "-------\n",
      "scores : ndarray of float of shape=(len(list(cv)),)\n",
      "    Array of scores of the estimator for each run of the cross validation.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn import datasets, linear_model\n",
      ">>> from sklearn.model_selection import cross_val_score\n",
      ">>> diabetes = datasets.load_diabetes()\n",
      ">>> X = diabetes.data[:150]\n",
      ">>> y = diabetes.target[:150]\n",
      ">>> lasso = linear_model.Lasso()\n",
      ">>> print(cross_val_score(lasso, X, y, cv=3))\n",
      "[0.33150734 0.08022311 0.03531764]\n",
      "\n",
      "See Also\n",
      "---------\n",
      "cross_validate : To run cross-validation on multiple metrics and also to\n",
      "    return train scores, fit times and score times.\n",
      "\n",
      "cross_val_predict : Get predictions from each split of cross-validation for\n",
      "    diagnostic purposes.\n",
      "\n",
      "sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      "    loss function.\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\programdata\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "?cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo\n",
    "scores = cross_val_score(bagging, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média do score\n",
    "mean = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91944444 0.92777778 0.94428969 0.96935933 0.94150418]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9404750851129681\n"
     ]
    }
   ],
   "source": [
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extremely Randomized Trees (ExtraTrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento\n",
    "data = scale(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis preditoras e variável target\n",
    "X = data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78055556 0.71388889 0.80779944 0.8356546  0.79665738]\n",
      "0.7869111730114515\n"
     ]
    }
   ],
   "source": [
    "# Cria o classificador\n",
    "clf = DecisionTreeClassifier(max_depth = None, min_samples_split = 2, random_state = 0)\n",
    "scores = cross_val_score(clf, X, y)\n",
    "mean = scores.mean()\n",
    "print(scores)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89166667 0.88055556 0.91643454 0.93036212 0.90807799]\n",
      "0.9054193748065614\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 10, max_depth = None, min_samples_split = 2, random_state = 0)\n",
    "scores = cross_val_score(clf, X, y)\n",
    "mean = scores.mean()\n",
    "print(scores)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90277778 0.86944444 0.93593315 0.95264624 0.91364903]\n",
      "0.9148901268956979\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators = 10, max_depth = None, min_samples_split = 2, random_state = 0)\n",
    "scores = cross_val_score(clf, X, y)\n",
    "mean = scores.mean()\n",
    "print(scores)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#from sklearn.datasets.mldata import fetch_mldata\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregandos os dados\n",
    "data = load_digits()\n",
    "# Pré-processamento\n",
    "data = scale(digits.data)\n",
    "# Variáveis preditoras e variável target\n",
    "X = data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets de treino e de teste\n",
    "X_test, y_test = X[189:], y[189:]\n",
    "X_train, y_train = X[:189], y[:189]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo o estimador base\n",
    "estim_base = DecisionTreeClassifier(max_depth = 1, min_samples_leaf = 1)\n",
    "estim_base.fit(X_train, y_train)\n",
    "estim_base_err = 1.0 - estim_base.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(base_estimator = estim_base, learning_rate = 1.0, n_estimators = 400, algorithm = \"SAMME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "                   base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   n_estimators=400)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82919255 0.75776398 0.8757764  0.8317757  0.82242991]\n",
      "0.8233877053462587\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(ada_clf, X_test, y_test)\n",
    "print(scores)\n",
    "means = scores.mean()\n",
    "print(means)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
