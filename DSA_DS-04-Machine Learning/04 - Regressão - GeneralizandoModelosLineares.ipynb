{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalizando Modelos Lineares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo de qualquer modelo de Machine Learning é generalizar para novoso conjuntos de dados. Não criamos o modelo para os dados de treino e sim para novos dados. Por isso é importante encontrar os melhores parâmertros para o modelo, que permitirão generalizar para novos dados. Existem diversas técnicas de regularização, de acordo com o modelo. Abaixo as 3 principais técnicas de regularização para modelos lineares: Ridge, LASSO e ElasticNet.\n",
    "\n",
    "> http://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.model_selection  import cross_val_score, KFold, StratifiedKFold\n",
    "#import sklearn.metrics\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de dados e definição de variáveis  \n",
    "boston = load_boston() \n",
    "dataset = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "dataset['target'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "observations = len(dataset)\n",
    "variables = dataset.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis X e Y\n",
    "X = dataset.iloc[:,:-1]\n",
    "y = dataset['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Dados de treino e de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do Dataset de Treino: 354\n",
      "Tamanho do Dataset de Teste: 152\n"
     ]
    }
   ],
   "source": [
    "print (\"Tamanho do Dataset de Treino: %i\" % len(X_train))\n",
    "print (\"Tamanho do Dataset de Teste: %i\" % len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Amostras de Treino, Validação e Teste\n",
    "X_train, X_out_sample, y_train, y_out_sample = train_test_split(X, y, test_size = 0.40, random_state = 101)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_out_sample, y_out_sample, test_size = 0.50, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamamnho da Amostra do Dataset de Treino: 303\n",
      "Tamamnho da Amostra do Dataset de Validação: 101\n",
      "Tamamnho da Amostra do Dataset de Teste: 102\n"
     ]
    }
   ],
   "source": [
    "print (\"Tamamnho da Amostra do Dataset de Treino: %i\" % len(X_train))\n",
    "print (\"Tamamnho da Amostra do Dataset de Validação: %i\" % len(X_validation))\n",
    "print (\"Tamamnho da Amostra do Dataset de Teste: %i\" % len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Calcula o RMSE\n",
    "def RMSE(y_true, y_pred):\n",
    "    return np.sum((y_true - y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o regressor linear\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Divide as amostras em grupos\n",
    "#cv_iterator = KFold(n = len(X), n_folds = 10, shuffle = True, random_state = 101)\n",
    "cv_iterator = KFold(10, shuffle = True, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5., 14., 23., 32., 41., 50.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define os limites do histograma\n",
    "edges = np.histogram(y, bins = 5)[1]\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 4, 4, 4, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2,\n",
       "       2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 3, 3, 4, 3, 3, 3,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 4, 3, 3, 3, 2, 2, 2, 2, 3, 4, 3,\n",
       "       2, 2, 2, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 3, 2, 2,\n",
       "       3, 3, 2, 2, 2, 3, 2, 3, 2, 4, 5, 4, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 1, 5, 3, 3, 3, 6, 6, 6, 2, 3, 6, 3, 3, 2, 2, 2, 3, 3, 2, 3,\n",
       "       3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 6, 4, 3, 4, 4, 3, 4, 3, 3, 6, 4, 3,\n",
       "       4, 4, 4, 3, 5, 5, 6, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 3,\n",
       "       3, 2, 3, 3, 5, 6, 4, 3, 5, 3, 3, 3, 5, 5, 3, 3, 3, 3, 3, 3, 2, 2,\n",
       "       2, 3, 2, 2, 3, 2, 3, 3, 3, 3, 3, 5, 2, 2, 5, 6, 4, 3, 4, 5, 5, 3,\n",
       "       4, 2, 3, 6, 5, 2, 2, 3, 3, 4, 4, 4, 4, 4, 3, 4, 5, 4, 5, 6, 4, 2,\n",
       "       2, 3, 2, 3, 3, 4, 3, 3, 2, 3, 3, 2, 2, 3, 3, 2, 3, 4, 4, 3, 4, 3,\n",
       "       2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 2, 2, 3, 3, 3, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 3, 3, 2, 2, 3, 3, 3, 2, 3,\n",
       "       2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 3, 6, 6, 6, 6, 6, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 3, 2, 2, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3, 2,\n",
       "       2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retorna os índices dos compartimentos (bins) aos quais pertence cada valor na matriz de entrada.\n",
    "binning = np.digitize(y, edges)\n",
    "binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Divide as amostras em grupos com a mesma percentagem\n",
    "#stratified_cv_iterator = StratifiedKFold(10, shuffle = True, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um padrão comum no aprendizado da máquina é usar modelos lineares treinados em funções não-lineares dos dados. Esta abordagem mantém o desempenho geralmente rápido dos métodos lineares, enquanto permite que eles se ajustem a uma gama muito maior de dados. Por exemplo, uma regressão linear simples pode ser estendida construindo características polinomiais a partir dos coeficientes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combinação polinomial de todos os atributos\n",
    "# Gera uma nova matriz de características constituída por todas as combinações polinomiais \n",
    "# das características com grau menor ou igual ao grau especificado.\n",
    "second_order = PolynomialFeatures(degree = 2, interaction_only = False)\n",
    "second_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.preprocessing._data.PolynomialFeatures"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(second_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures(degree=3, interaction_only=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combinação polinomial de todos os atributos\n",
    "third_order = PolynomialFeatures(degree = 3, interaction_only = True)\n",
    "third_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 6.32000000e-03, 1.80000000e+01, ...,\n",
       "        1.57529610e+05, 1.97656200e+03, 2.48004000e+01],\n",
       "       [1.00000000e+00, 2.73100000e-02, 0.00000000e+00, ...,\n",
       "        1.57529610e+05, 3.62766600e+03, 8.35396000e+01],\n",
       "       [1.00000000e+00, 2.72900000e-02, 0.00000000e+00, ...,\n",
       "        1.54315409e+05, 1.58310490e+03, 1.62409000e+01],\n",
       "       ...,\n",
       "       [1.00000000e+00, 6.07600000e-02, 0.00000000e+00, ...,\n",
       "        1.57529610e+05, 2.23851600e+03, 3.18096000e+01],\n",
       "       [1.00000000e+00, 1.09590000e-01, 0.00000000e+00, ...,\n",
       "        1.54802902e+05, 2.54955600e+03, 4.19904000e+01],\n",
       "       [1.00000000e+00, 4.74100000e-02, 0.00000000e+00, ...,\n",
       "        1.57529610e+05, 3.12757200e+03, 6.20944000e+01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando a combinação polinominal grau 2 aos atributos de entrada\n",
    "over_param_X = second_order.fit_transform(X)\n",
    "over_param_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 6.32000000e-03, 1.80000000e+01, ...,\n",
       "        2.25534240e+04, 5.85062352e+05, 3.02413986e+04],\n",
       "       [1.00000000e+00, 2.73100000e-02, 0.00000000e+00, ...,\n",
       "        3.93714640e+04, 8.77895172e+05, 6.45724548e+04],\n",
       "       [1.00000000e+00, 2.72900000e-02, 0.00000000e+00, ...,\n",
       "        1.73596280e+04, 3.83111386e+05, 2.81792672e+04],\n",
       "       ...,\n",
       "       [1.00000000e+00, 6.07600000e-02, 0.00000000e+00, ...,\n",
       "        3.23341200e+04, 6.11114868e+05, 4.70088360e+04],\n",
       "       [1.00000000e+00, 1.09590000e-01, 0.00000000e+00, ...,\n",
       "        3.71498400e+04, 6.96028788e+05, 5.35406760e+04],\n",
       "       [1.00000000e+00, 4.74100000e-02, 0.00000000e+00, ...,\n",
       "        4.51760400e+04, 8.53827156e+05, 6.56790120e+04]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando a combinação polinominal grau 3 aos atributos de entrada\n",
    "extra_over_param_X = third_order.fit_transform(X)\n",
    "extra_over_param_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Gerando o Score. Variáveis de entrada (X) com pré-processamento polinomial\n",
    "cv_score = cross_val_score(lm, over_param_X, y, cv = cv_iterator, scoring = 'neg_mean_squared_error', n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-11.67358612 -22.84201585  -9.19318785 -19.77458934 -11.68472903\n",
      "  -9.15302456 -12.97982141 -22.18260706 -35.93064657 -13.75241158]\n"
     ]
    }
   ],
   "source": [
    "print (cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cv score: mean 16.917 std 7.955\n"
     ]
    }
   ],
   "source": [
    "print ('Cv score: mean %0.3f std %0.3f' % (np.mean(np.abs(cv_score)), np.std(cv_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#cv_score = cross_val_score(lm, over_param_X, y, cv = stratified_cv_iterator, scoring = 'neg_mean_squared_error', n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#print ('Cv score: mean %0.3f std %0.3f' % (np.mean(np.abs(cv_score)), np.std(cv_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas de Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularização\n",
    "\n",
    "De uma maneira bem direta, podemos entender regularização como a inserção de bias em um modelo. Ou em outras palavras, essa técnica desencoraja o ajuste excessivo dos dados, afim de diminuir a sua variância.\n",
    "\n",
    "Dentro da regressão linear, Ridge e Lasso são formas de regularizarmos a nossa função através de penalidades. De forma simples, dentro de uma equação estatística dos dados, nós alteramos os fatores de forma a priorizar ou não certas parcelas da equação e, assim, evitamos ‘overfitting’ e melhoramos a qualidade de predição.\n",
    "\n",
    "**Os parâmetros L1 e L2**<br/>\n",
    "Uma regressão linear tenta ajustar uma função linear aos dados. O procedimento de ajuste envolve a função de custo como soma residual dos quadrados ou RSS. Os coeficientes w são escolhidos para minimizar essa função de custo com base nos dados de treinamento.<br/> \n",
    " \n",
    "No entanto, pode ocorrer overfitting, ou seja, o modelo pode “memorizar” o ruído dos dados de treinamento. Nesse caso, dizemos que o modelo tem um erro de generalização (erro na base de teste) elevado. Esse fenômeno está associado à variância do modelo, como vimos acima. Portanto, uma forma de diminuir o erro é aumentar o bias.<br/>\n",
    " \n",
    "Para isso, regularizamos os coeficientes w, ou seja, restringimos o seu tamanho. Isso é feito adicionando um termo na função de custo, de forma que minimizar a função de custo automaticamente minimize também os coeficientes.\n",
    "\n",
    "**Lasso (ou L1)**<br/>\n",
    "Além de diminuir a variância do modelo, essa regularização tem uma outra importante aplicação em machine learning. Quando há múltiplas features altamente correlacionadas (ou seja, features que se comportam da mesma maneira) a regularização Lasso seleciona apenas uma dessas features e zera os coeficientes das outras, de forma a minimizar a penalização L1. Desse modo, dizemos que esse modelo realiza feature selection automaticamente, gerando vários coeficientes com peso zero, ou seja, que são ignorados pelo modelo. Isso facilita a interpretação do modelo, o que é uma enorme vantagem.\n",
    "\n",
    "**Ridge (ou L2)**<br/>\n",
    "Nesse caso, a penalização consiste nos quadrados dos coeficientes, ao invés de seus módulos. Qual será o efeito dessa regularização nos coeficientes de duas features altamente correlacionadas? Poderíamos ter duas features com coeficientes parecidos, ou uma com coeficiente alto, e outra com coeficiente zero. Como a penalização L2 é desproporcionalmente maior para coeficientes maiores, a regularização Ridge faz com que features correlacionadas tenham coeficientes parecidos.\n",
    "\n",
    "No entanto, essa regularização não diminui a susceptibilidade do modelo a outliers, de forma que é recomendável limpar o dataset e remover features desnecessárias antes de realizar esse tipo de regressão.\n",
    "\n",
    "Em termos matemáticos, a penalidade L1 não é diferenciável, o que pode complicar a sua implementação. Já a L2 é diferenciável, o que significa que ela pode ser usada em abordagens baseadas em gradiente.\n",
    "\n",
    "**Elastic Net — L1+L2**<br/>\n",
    "Sim, se trata exatamente de combinar os termos de regularização de L1 e L2. Assim, obtemos o melhor dos dois mundos, porém temos que enfrentar o problema de determinar dois hiperparâmetros para obter soluções ótimas.\n",
    "\n",
    "**Referência:**<br/>\n",
    "> DEVAY, Andre. *Modelos de Predição | Regressão de Ridge e Lasso*. Disponível em: https://medium.com/turing-talks/turing-talks-20-regressão-de-ridge-e-lasso-a0fc467b5629"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Cria o regressor Ridge\n",
    "ridge = Ridge(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(normalize=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplica o fit (Ridge) às variáveis\n",
    "ridge.fit(second_order.fit_transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplica o fit (Linear Regression) às variáveis\n",
    "lm.fit(second_order.fit_transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média dos Coeficientes: Não-regularizado = 7592022.977 Ridge = -0.027\n",
      "Coeficiente Mínimo: Não-regularizado = -35.002 Ridge = -2.011\n",
      "Max coefficient: Não-regularizado = 797162270.345 Ridge = 1.181\n"
     ]
    }
   ],
   "source": [
    "# Comparação entre os coeficentes não regularizados (Linear Regression) e regularizados (Ridge)\n",
    "# O objetivo da regularização é generalizar o modelo para novos conjuntos de dados\n",
    "print ('Média dos Coeficientes: Não-regularizado = %0.3f Ridge = %0.3f' % (np.mean(lm.coef_), np.mean(ridge.coef_)))\n",
    "print ('Coeficiente Mínimo: Não-regularizado = %0.3f Ridge = %0.3f' % (np.min(lm.coef_), np.min(ridge.coef_)))\n",
    "print ('Max coefficient: Não-regularizado = %0.3f Ridge = %0.3f' % (np.max(lm.coef_), np.max(ridge.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o regressor LASSO\n",
    "lasso_reg = Lasso(alpha = 1.0, normalize = True, max_iter = 2*10**5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Random seed para garantir a reproducibilidade\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide as amostras em grupos com a mesma percentagem\n",
    "cv_iterator = KFold(10, shuffle = True, random_state = 101)\n",
    "#stratified_cv_iterator = StratifiedKFold(10, shuffle = True, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Busca pela melhor combinação de parâmetros testando diversos valores de alfa: {'alpha':np.logspace(-5,2,100)}\n",
    "# A função RandomizedSearchCV gera o modelo como resultado\n",
    "func_busca = RandomizedSearchCV(estimator = lasso_reg, \n",
    "                                param_distributions = {'alpha':np.logspace(-5,2,100)}, \n",
    "                                n_iter = 10, \n",
    "                                scoring='neg_mean_squared_error', \n",
    "                                n_jobs = 1, \n",
    "                                #iid = False, \n",
    "                                refit = True, \n",
    "                                cv = cv_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=10, random_state=101, shuffle=True),\n",
       "                   estimator=Lasso(max_iter=200000, normalize=True), n_jobs=1,\n",
       "                   param_distributions={'alpha': array([1.00000000e-05, 1.17681195e-05, 1.38488637e-05, 1.62975083e-05,\n",
       "       1.91791026e-05, 2.25701972e-05, 2.65608778e-05, 3.12571585e-05,\n",
       "       3.67837977e-05, 4.32876128e-05, 5.09413801e-05, 5.99484250e-05,\n",
       "       7.0548...\n",
       "       2.36448941e+00, 2.78255940e+00, 3.27454916e+00, 3.85352859e+00,\n",
       "       4.53487851e+00, 5.33669923e+00, 6.28029144e+00, 7.39072203e+00,\n",
       "       8.69749003e+00, 1.02353102e+01, 1.20450354e+01, 1.41747416e+01,\n",
       "       1.66810054e+01, 1.96304065e+01, 2.31012970e+01, 2.71858824e+01,\n",
       "       3.19926714e+01, 3.76493581e+01, 4.43062146e+01, 5.21400829e+01,\n",
       "       6.13590727e+01, 7.22080902e+01, 8.49753436e+01, 1.00000000e+02])},\n",
       "                   scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplica o modelo criado aos datasets\n",
    "# Esta operação leva algum tempo para ser executada.....\n",
    "func_busca.fit(second_order.fit_transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 0.00014\n",
      "Melhor CV mean squared error: 13.357\n"
     ]
    }
   ],
   "source": [
    "# Imprime os resultados\n",
    "print ('Melhor valor de alpha: %0.5f' % func_busca.best_params_['alpha'])\n",
    "print ('Melhor CV mean squared error: %0.3f' % np.abs(func_busca.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficients com valor igual a zero: 76 de 105\n"
     ]
    }
   ],
   "source": [
    "print ('Coeficients com valor igual a zero: %i de %i' % (np.sum(~(func_busca.best_estimator_.coef_ == 0.0)), len(func_busca.best_estimator_.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Aplica a regularização Lasso com Cross Validation (o melhor modelo é selecionado por Cross Validation)\n",
    "lasso_reg_cv = LassoCV(alphas = np.logspace(-5,2,100), normalize = True, n_jobs = 1, cv = None, max_iter = 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=array([1.00000000e-05, 1.17681195e-05, 1.38488637e-05, 1.62975083e-05,\n",
       "       1.91791026e-05, 2.25701972e-05, 2.65608778e-05, 3.12571585e-05,\n",
       "       3.67837977e-05, 4.32876128e-05, 5.09413801e-05, 5.99484250e-05,\n",
       "       7.05480231e-05, 8.30217568e-05, 9.77009957e-05, 1.14975700e-04,\n",
       "       1.35304777e-04, 1.59228279e-04, 1.87381742e-04, 2.20513074e-04,\n",
       "       2.59502421e-04, 3.05385551e-0...\n",
       "       2.36448941e+00, 2.78255940e+00, 3.27454916e+00, 3.85352859e+00,\n",
       "       4.53487851e+00, 5.33669923e+00, 6.28029144e+00, 7.39072203e+00,\n",
       "       8.69749003e+00, 1.02353102e+01, 1.20450354e+01, 1.41747416e+01,\n",
       "       1.66810054e+01, 1.96304065e+01, 2.31012970e+01, 2.71858824e+01,\n",
       "       3.19926714e+01, 3.76493581e+01, 4.43062146e+01, 5.21400829e+01,\n",
       "       6.13590727e+01, 7.22080902e+01, 8.49753436e+01, 1.00000000e+02]),\n",
       "        max_iter=1000000, n_jobs=1, normalize=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "# Esta operação leva algum tempo para ser executada.....\n",
    "lasso_reg_cv.fit(second_order.fit_transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 0.00413\n"
     ]
    }
   ],
   "source": [
    "# Imprime os resultados\n",
    "print ('Melhor valor de alpha: %0.5f' % lasso_reg_cv.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Cria o regressor ElasrticNet\n",
    "elasticnet_reg = ElasticNet(alpha = 1.0, l1_ratio = 0.15, normalize = True, max_iter = 10**6, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca pela melhor combinação de parâmetros testando diversos valores de alfa: {'alpha':np.logspace(-5,2,100)}\n",
    "# A função RandomizedSearchCV gera o modelo como resultado\n",
    "func_busca = RandomizedSearchCV(estimator = elasticnet_reg, \n",
    "                                param_distributions = {'alpha':np.logspace(-5,2,100), \n",
    "                                                       'l1_ratio':np.arange(0.0, 1.01, 0.05)}, \n",
    "                                n_iter = 10, \n",
    "                                scoring = 'neg_mean_squared_error', \n",
    "                                n_jobs = 1, \n",
    "                                #iid = False, \n",
    "                                refit = True, \n",
    "                                cv = cv_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=10, random_state=101, shuffle=True),\n",
       "                   estimator=ElasticNet(l1_ratio=0.15, max_iter=1000000,\n",
       "                                        normalize=True, random_state=101),\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={'alpha': array([1.00000000e-05, 1.17681195e-05, 1.38488637e-05, 1.62975083e-05,\n",
       "       1.91791026e-05, 2.25701972e-05, 2.65608778e-05, 3.12571585e-05,\n",
       "       3.67837977e-05, 4.32876128e-05...\n",
       "       8.69749003e+00, 1.02353102e+01, 1.20450354e+01, 1.41747416e+01,\n",
       "       1.66810054e+01, 1.96304065e+01, 2.31012970e+01, 2.71858824e+01,\n",
       "       3.19926714e+01, 3.76493581e+01, 4.43062146e+01, 5.21400829e+01,\n",
       "       6.13590727e+01, 7.22080902e+01, 8.49753436e+01, 1.00000000e+02]),\n",
       "                                        'l1_ratio': array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
       "       0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])},\n",
       "                   scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "func_busca.fit(second_order.fit_transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 0.00002\n",
      "Melhor L1_ratio: 0.60000\n",
      "Melhor CV mean squared error: 12.987\n"
     ]
    }
   ],
   "source": [
    "# Resultados\n",
    "print ('Melhor valor de alpha: %0.5f' % func_busca.best_params_['alpha'])\n",
    "print ('Melhor L1_ratio: %0.5f' % func_busca.best_params_['l1_ratio'])\n",
    "print ('Melhor CV mean squared error: %0.3f' % np.abs(func_busca.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficients com valor igual a zero: 102 de 105\n"
     ]
    }
   ],
   "source": [
    "# Coeficientes \n",
    "print ('Coeficients com valor igual a zero: %i de %i' % (np.sum(~(func_busca.best_estimator_.coef_ == 0.0)), \n",
    "                                                         len(func_busca.best_estimator_.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Aplica a regularização ElasticNet com Cross Validation (o melhor modelo é selecionado por Cross Validation)\n",
    "elasticnet_reg_cv = ElasticNetCV(alphas = np.logspace(-5,2,100), \n",
    "                                 normalize = True, \n",
    "                                 n_jobs = 1, \n",
    "                                 cv = None, \n",
    "                                 max_iter = 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(alphas=array([1.00000000e-05, 1.17681195e-05, 1.38488637e-05, 1.62975083e-05,\n",
       "       1.91791026e-05, 2.25701972e-05, 2.65608778e-05, 3.12571585e-05,\n",
       "       3.67837977e-05, 4.32876128e-05, 5.09413801e-05, 5.99484250e-05,\n",
       "       7.05480231e-05, 8.30217568e-05, 9.77009957e-05, 1.14975700e-04,\n",
       "       1.35304777e-04, 1.59228279e-04, 1.87381742e-04, 2.20513074e-04,\n",
       "       2.59502421e-04, 3.053855...\n",
       "       2.36448941e+00, 2.78255940e+00, 3.27454916e+00, 3.85352859e+00,\n",
       "       4.53487851e+00, 5.33669923e+00, 6.28029144e+00, 7.39072203e+00,\n",
       "       8.69749003e+00, 1.02353102e+01, 1.20450354e+01, 1.41747416e+01,\n",
       "       1.66810054e+01, 1.96304065e+01, 2.31012970e+01, 2.71858824e+01,\n",
       "       3.19926714e+01, 3.76493581e+01, 4.43062146e+01, 5.21400829e+01,\n",
       "       6.13590727e+01, 7.22080902e+01, 8.49753436e+01, 1.00000000e+02]),\n",
       "             max_iter=1000000, n_jobs=1, normalize=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "elasticnet_reg_cv.fit(second_order.fit_transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 0.00132\n",
      "Melhor L1_ratio: 0.50000\n"
     ]
    }
   ],
   "source": [
    "# Resultados\n",
    "print ('Melhor valor de alpha: %0.5f' % elasticnet_reg_cv.alpha_)\n",
    "print ('Melhor L1_ratio: %0.5f' % elasticnet_reg_cv.l1_ratio_)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
