{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo um Classificador Naive Bayes em Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos construindo um classificador Naive Bayes com BernoulliNB e MultinomialNB em Python. Não usaremos as funções do Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import logging\n",
    "import sys\n",
    "from time import time\n",
    "from math import *\n",
    "from matplotlib import pyplot as pl\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBernClassifier():\n",
    "  \n",
    "    def __init__(self, smooth = 1):\n",
    "        self._smooth = smooth \n",
    "        self._feat_prob = []\n",
    "        self._class_prob = []\n",
    "        self._Ncls = []\n",
    "        self._Nfeat = []\n",
    "\n",
    "    def train(self, X, y):\n",
    "        print (\"Treinando Bernoulli NB...\")\n",
    "        count_each_class = {}\n",
    "        feature_count = {}\n",
    "        alpha = self._smooth \n",
    "        temp = []\n",
    "        temp.append(np.unique(y))\n",
    "        self._Ncls.append(temp[0].size) # Número total de classes\n",
    "        self._Nfeat.append(X[0].size)  # Número total de features\n",
    "        \n",
    "        for i in range(y.size):\n",
    "            if y[i] in feature_count:\n",
    "                continue\n",
    "            else:\n",
    "                feature_count[y[i]] = [0 for w in range (X[i].size)]\n",
    "                \n",
    "\n",
    "        # Conta os atributos para cada classe através do treinamento ou \n",
    "        # conta a ocorrência de cada classe através do treinamento\n",
    "        for i in range (y.size):\n",
    "            if y[i] in count_each_class:\n",
    "                count_each_class[y[i]] +=1\n",
    "            else:\n",
    "                count_each_class[y[i]] = 1\n",
    "            for j in  range(X[i].size):\n",
    "                    feature_count[y[i]][j] += X[i][j]\n",
    "                    \n",
    "        # Calcula probabilidades de classe e atributos para cada classe      \n",
    "        for cls in feature_count:\n",
    "            \n",
    "            num = (self._smooth+count_each_class[cls])\n",
    "            din = (y.size+(self._Ncls[0]*self._smooth))\n",
    "            self._class_prob.append((num/float(din)))\n",
    "            ar = np.array([])\n",
    "            for j in  range(X[i].size):\n",
    "                \n",
    "                num = (feature_count[cls][j] + self._smooth)\n",
    "                din = (count_each_class[cls]+(2*self._smooth))\n",
    "                ar = np.append(ar,(num/float(din)))\n",
    "            self._feat_prob.append(ar)\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        print (\"Fazendo Previsões com Bernoulli NB...\")\n",
    "        \n",
    "        Y_predict = np.array([])\n",
    "\n",
    "        for i in X:\n",
    "            neg_log_prob = 0\n",
    "            minimum_neg_log_prob = 999999999999999\n",
    "            category = 0  \n",
    "                \n",
    "            for cls in range(self._Ncls[0]):\n",
    "                neg_log_prob = -log(self._class_prob[cls])\n",
    "                for j in  range(self._Nfeat[0]):  \n",
    "                    if (i[j])==0:\n",
    "                        neg_log_prob -= log(1-self._feat_prob[cls][j])\n",
    "                    else:\n",
    "                        neg_log_prob -= log(self._feat_prob[cls][j])\n",
    "                        \n",
    "                if minimum_neg_log_prob>neg_log_prob:\n",
    "                    category=cls\n",
    "                    minimum_neg_log_prob=neg_log_prob\n",
    "            \n",
    "            Y_predict=np.append(Y_predict,category)\n",
    "         \n",
    "        return Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultinomialBayesClassifier():\n",
    "    \n",
    "    def __init__(self, smooth = 1):\n",
    "        self._smooth = smooth \n",
    "        self._feat_prob = []\n",
    "        self._class_prob = []\n",
    "        self._class_neg_prob = []\n",
    "        self._Ncls = []\n",
    "        self._Nfeat = []\n",
    "\n",
    "    def train(self, X, y):\n",
    "        print (\"Treinando Multinomial NB...\")\n",
    "        \n",
    "        count_each_class = {}\n",
    "        feature_count = {}\n",
    "      \n",
    "        for i in range(y.size):\n",
    "            if y[i] in feature_count:\n",
    "                continue\n",
    "            else:\n",
    "                feature_count[y[i]] = [0 for w in range (X[i].size)]\n",
    "                \n",
    "        for i in range (y.size):\n",
    "            if y[i] in count_each_class:\n",
    "                count_each_class[y[i]] +=1\n",
    "            else:\n",
    "                count_each_class[y[i]] = 1\n",
    "            for j in  range(X[i].size):\n",
    "                    feature_count[y[i]][j] += X[i][j]\n",
    "                \n",
    "        alpha = self._smooth \n",
    "        temp = []\n",
    "        temp.append(np.unique(y))\n",
    "        self._Ncls.append(temp[0].size)\n",
    "        self._Nfeat.append(X[0].size)  \n",
    "        self._class_prob.append(count_each_class)\n",
    "        self._feat_prob.append(feature_count)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        print (\"Fazendo Previsões com Multinomial NB...\")\n",
    "        \n",
    "        Y_predict = np.array([])\n",
    "        \n",
    "        # Calcula o total de classes para os dados de treino\n",
    "        total_train_count = 0\n",
    "        for key in self._class_prob[0]:\n",
    "            total_train_count += self._class_prob[0][key]\n",
    "        \n",
    "        for i in X:\n",
    "            neg_log_prob = 0\n",
    "            minimum_neg_log_prob=999999999999999\n",
    "            category = 0\n",
    "            \n",
    "            for cls in self._feat_prob[0]:\n",
    "                Ny = sum(self._feat_prob[0][cls])\n",
    "                neg_log_prob = -log((self._class_prob[0][cls]+1)/float(total_train_count+(self._Ncls[0]*self._smooth)))\n",
    "                for j in  range(self._Nfeat[0]):  \n",
    "                    if (i[j])==0:\n",
    "                        continue    \n",
    "                    for itere in range (i[j]):\n",
    "                        num = (self._smooth+self._feat_prob[0][cls][j])\n",
    "                        din = (Ny+(self._Nfeat[0]*self._smooth))\n",
    "                        neg_log_prob -= log(num/float(din))\n",
    "                        \n",
    "                if minimum_neg_log_prob>neg_log_prob:\n",
    "                    category=cls\n",
    "                    minimum_neg_log_prob=neg_log_prob\n",
    "            \n",
    "            Y_predict=np.append(Y_predict,category)\n",
    "         \n",
    "        return Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as classes que serão usadas no processo de classificação\n",
    "categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space',\n",
    "    ]\n",
    "remove = ('headers', 'footers', 'quotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados Carregados!\n"
     ]
    }
   ],
   "source": [
    "# Carrega os dados\n",
    "data_train = fetch_20newsgroups(subset = 'train', categories = categories, shuffle = True, random_state = 42, remove = remove)\n",
    "data_test = fetch_20newsgroups(subset = 'test', categories = categories, shuffle = True, random_state = 42, remove = remove)\n",
    "print('Dados Carregados!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino e Teste\n",
    "y_train, y_test = data_train.target, data_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo as features do dataset de treino usando o count vectorizer\n"
     ]
    }
   ],
   "source": [
    "print(\"Extraindo as features do dataset de treino usando o count vectorizer\")\n",
    "t0 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary = true for Bernoulli NB\n",
    "vectorizer = CountVectorizer(stop_words = 'english', binary = True)\n",
    "X_train = vectorizer.fit_transform(data_train.data).toarray()\n",
    "X_test = vectorizer.transform(data_test.data).toarray()\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "Tempo esperado para execução do modelo Bernoulli NB é 180 seg\n",
      "Treinando Bernoulli NB...\n",
      "Fazendo Previsões com Bernoulli NB...\n",
      "Para o modelo Bernoulli NB:  alpha = 1.000000, accuracy = 0.310421\n",
      "Tempo total para treinar e prever com o modelo Bernoulli: 150.44519805908203\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# For Bernoulli NB, Binary = true, train for one default smooth value alpha = 1\n",
    "\n",
    "print ('-------------------------------------------------------------')\n",
    "print ('Tempo esperado para execução do modelo Bernoulli NB é 180 seg')\n",
    "ta = time()\n",
    "alpha = 1\n",
    "clf = MyBernClassifier(alpha)\n",
    "clf.train(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "tb = time()\n",
    "print (\"Para o modelo Bernoulli NB:  \" +'alpha = %f, accuracy = %f' %(alpha, np.mean((y_test - y_pred)==0)))\n",
    "print (\"Tempo total para treinar e prever com o modelo Bernoulli: \" + str(tb-ta))\n",
    "print ('-------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esta célula pode levar horas para ser executada!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli Naive bayes: Alpha Vs accuracy\n",
    "acc = []\n",
    "alp = []\n",
    "\n",
    "for alpha in [float(j) / 100 for j in range(1, 101, 1)]:\n",
    "    print ('-----------------------------------------------------------------------------------------------------')\n",
    "    ta = time()\n",
    "    clf = MyBernClassifier(alpha)\n",
    "    clf.train(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc.append(np.mean((y_test-y_pred)==0))\n",
    "    alp.append(alpha)\n",
    "    tb = time()\n",
    "    print (\"Tempo de treinamento: \" + str(tb-ta) + \" acurácia, alpha is: \" + str(np.mean((y_test-y_pred)==0)) +\",\"+str(alpha))\n",
    "\n",
    "# Plotting \n",
    "with PdfPages('Bernoulli.pdf') as pdf:\n",
    "    pl.plot(alp,acc,marker='.', linestyle = '-', color = 'r')\n",
    "    pl.ylabel('Acurácia',color='g')\n",
    "    pl.xlabel('Alpha',color='g')\n",
    "    pl.title('Plot Alpha Vs Acurácia para Bernoulli NB',color = 'r')\n",
    "    pdf.savefig() \n",
    "    pl.close()\n",
    "\n",
    "# Print\n",
    "print (\"Acurácia máxima do modelo Bernoulli NB is: \" + str(max(acc)))\n",
    "print (\"com valor correspondente para alpha de:       \" + str(alp[(acc.index(max(acc)))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary = false para Multinomial NB\n",
    "\n",
    "print (\"Extraindo dados com Binary = False para Multinomial NB\")\n",
    "vectorizer = CountVectorizer(stop_words = 'english', binary = False)\n",
    "X_train = vectorizer.fit_transform(data_train.data).toarray()\n",
    "X_test = vectorizer.transform(data_test.data).toarray()\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "print ('Tempo total esperado para execução do Multinomial NB é 90 seg')\n",
    "ta = time()\n",
    "alpha = 1\n",
    "clf1 = MyMultinomialBayesClassifier(alpha)\n",
    "clf1.train(X_train,y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "\n",
    "print (\"Para modelo Multinomial NB:  \" +'alpha = %f accuracy = %f' %(alpha, np.mean((y_test-y_pred)==0)))\n",
    "tb = time()\n",
    "print (\"Tempo total para treinar e prever o modelo Multinomial: \" + str(tb-ta))\n",
    "print ('--------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esta célula pode levar horas para ser executada!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multionomial Naive bayes: Alpha Vs accuracy \n",
    "acc = []\n",
    "alp = []\n",
    "\n",
    "for alpha in [float(j) / 100 for j in range(1, 101, 1)]:\n",
    "    print ('--------------------------------------------------------------------------------------')\n",
    "    ta = time()\n",
    "    clf1 = MyMultinomialBayesClassifier(alpha)\n",
    "    clf1.train(X_train,y_train)\n",
    "    y_pred1 = clf1.predict(X_test)\n",
    "    acc.append(np.mean((y_test-y_pred1)==0))\n",
    "    alp.append(alpha)\n",
    "    tb = time()\n",
    "    print (\"Tempo de Treinamento: \" + str(tb-ta) + \" acurácia, alpha é: \" + str(np.mean((y_test-y_pred1)==0)) +\",\"+str(alpha))\n",
    "    #print ('alpha=%f accuracy = %f' %(alpha, np.mean((y_test-y_pred1)==0)))\n",
    "\n",
    "# Plotting \n",
    "with PdfPages('multinomial.pdf') as pdf:\n",
    "    pl.plot(alp,acc,marker = '.', linestyle = '-', color = 'r')\n",
    "    pl.ylabel('Acurácia',color = 'g')\n",
    "    pl.xlabel('Alpha',color = 'g')\n",
    "    pl.title('Plot Alpha Vs Acurácia para Multinomial NB',color = 'r')\n",
    "    pdf.savefig() \n",
    "    pl.close()\n",
    "\n",
    "# Max Accuracy and Corresponding alpha.\n",
    "\n",
    "print (\"Acurácia máxima para o modelo Multinomial NB is: \" + str(max(acc)))\n",
    "print (\"com valor correspondente alpha de:       \" + str(alp[(acc.index(max(acc)))]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
